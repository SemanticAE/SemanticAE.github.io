<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- Replace with your paper title and author names -->
  <meta name="title" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction - Jin Hu, Jiakai Wang, Linna Jing, Haolin Li, Haodong Liu, Haotong Qin, Aishan Liu, Ke Xu, Xianglong Liu">
  <!-- Write a compelling 150-160 character description of your research -->
  <meta name="description" content="This paper introduces a framework to improve the generation of semantically constrained adversarial examples (SemanticAE) from natural language. By reducing instruction uncertainty, it produces more transferable, adaptive, and effective attacks, and for the first time, generates reference-free 3D adversarial examples.">
  <!-- Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="SemanticAE, diffusion models, instruction uncertainty, 3D adversarial examples, natural language guidance, transfer attack">
  <!-- List all authors -->
  <meta name="author" content="Jin Hu, Jiakai Wang, Linna Jing, Haolin Li, Haodong Liu, Haotong Qin, Aishan Liu, Ke Xu, Xianglong Liu">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- Replace with your institution or lab name -->
  <meta property="og:site_name" content="Beihang University, Zhongguancun Laboratory, ETH Zurich">
  <!-- Same as paper title above -->
  <meta property="og:title" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction">
  <!-- Same as description above -->
  <meta property="og:description" content="This paper introduces a framework to improve the generation of semantically constrained adversarial examples (SemanticAE) from natural language. By reducing instruction uncertainty, it produces more transferable, adaptive, and effective attacks, and for the first time, generates reference-free 3D adversarial examples.">
  <!-- Replace with your actual website URL -->
  <meta property="og:url" content="https://semanticae.github.io/">
  <!-- Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://semanticae.github.io/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction - Research Preview">
  <meta property="article:published_time" content="2025-09-20T00:00:00.000Z">
  <meta property="article:author" content="Jin Hu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="SemanticAE">
  <meta property="article:tag" content="3D adversarial examples">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- Same as paper title above -->
  <meta name="twitter:title" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction">
  <!-- Same as description above -->
  <meta name="twitter:description" content="This paper introduces a framework to improve the generation of semantically constrained adversarial examples (SemanticAE) from natural language. By reducing instruction uncertainty, it produces more transferable, adaptive, and effective attacks, and for the first time, generates reference-free 3D adversarial examples.">
  <!-- Same as social preview image above -->
  <meta name="twitter:image" content="https://semanticae.github.io/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction">
  <meta name="citation_author" content="Hu, Jin">
  <meta name="citation_author" content="Wang, Jiakai">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="NeurIPS">
  <meta name="citation_pdf_url" content="https://semanticae.github.io/static/pdfs/SemanticAE.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- Replace with your paper title and authors -->
  <title>Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction - Jin Hu, Jiakai Wang, Linna Jing, Haolin Li, Haodong Liu, Haotong Qin, Aishan Liu, Ke Xu, Xianglong Liu | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction",
    "description": "This paper introduces a framework to improve the generation of semantically constrained adversarial examples (SemanticAE) from natural language. By reducing instruction uncertainty, it produces more transferable, adaptive, and effective attacks, and for the first time, generates reference-free 3D adversarial examples.",
    "author": [
      {
        "@type": "Person",
        "name": "Jin Hu",
        "affiliation": {
          "@type": "Organization",
          "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Jiakai Wang",
        "affiliation": {
          "@type": "Organization",
          "name": "Zhongguancun Laboratory"
        }
      },
      {
        "@type": "Person",
        "name": "Linna Jing",
        "affiliation": {
          "@type": "Organization",
          "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Haolin Li",
        "affiliation": {
          "@type": "Organization",
          "name": "School of Computer Science and Engineering, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Haodong Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "School of Computer Science and Engineering, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Haotong Qin",
        "affiliation": {
          "@type": "Organization",
          "name": "Dept. of Information Technology and Electrical Engineering, ETH Zurich"
        }
      },
      {
        "@type": "Person",
        "name": "Aishan Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Ke Xu",
        "affiliation": {
          "@type": "Organization",
          "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
        }
      },
      {
        "@type": "Person",
        "name": "Xianglong Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
        }
      },
    ],
    "datePublished": "2025-09-20",
    "publisher": {
      "@type": "Organization",
      "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University"
    },
    "url": "https://semanticae.github.io",
    "image": "https://semanticae.github.io/static/images/social_preview.png",
    "keywords": ["SemanticAE", "diffusion models", "instruction uncertainty", "3D adversarial examples", "natural language guidance", "transfer attack"],
    "abstract": "Recently, semantically constrained adversarial examples (SemanticAE), which are directly generated from natural language instructions, have become a promising avenue for future research due to their flexible attacking forms, but have not been thoroughly explored yet. To generate SemanticAEs, current methods fall short of satisfactory attacking ability as the key underlying factors of semantic uncertainty in human instructions, such as referring diversity, descriptive incompleteness, and boundary ambiguity, have not been fully investigated. To tackle the issues, this paper develops a multi-dimensional instruction uncertainty reduction (InsUR) framework to generate more satisfactory SemanticAE, transferable, adaptive, and effective. Specifically, in the dimension of the sampling method, we propose the residual-driven attacking direction stabilization to alleviate the unstable adversarial optimization caused by the diversity of language references. By coarsely predicting the language-guided sampling process, the optimization process will be stabilized by the designed ResAdv-DDIM sampler, therefore releasing the transferable and robust adversarial capability of multi-step diffusion models. In task modeling, we propose the context-encoded attacking scenario constraint to supplement the missing knowledge from incomplete human instructions. Guidance masking and renderer integration are proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger scenario-adapted attacks. Moreover, in the dimension of generator evaluation, we propose the semantic-abstracted attacking evaluation enhancement by clarifying the evaluation boundary based on the label taxonomy, facilitating the development of more effective SemanticAE generators. Extensive experiments demonstrate the superiority of the transfer attack performance of InSUR. Besides, it is worth highlighting that we realize the reference-free generation of semantically constrained 3D adversarial examples by utilizing language-guided 3D generation models for the first time.",
    "citation": "@article{Hu2025SemanticAE,
  title={Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction},
  author={Hu, Jin and Wang, Jiakai and Jing, Linna and Li, Haolin and Liu, Haodong and Qin, Haotong and Liu, Aishan and Xu, Ke and Liu, Xianglong},
  journal={NeurIPS},
  year={2025}
}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://semanticae.github.io"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "State Key Laboratory of Complex & Critical Software Environment, Beihang University",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://github.com/YOUR_GITHUB_USERNAME",
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
        <div class="works-list">
         <a href="https://arxiv.org/abs/2406.04031" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt</h5>
            <p>This work introduces the Bi-Modal Adversarial Prompt Attack (BAP), which jailbreaks Large Vision Language Models (LVLMs) by cohesively optimizing both the textual and visual prompts to bypass safety guardrails.</p>
            <span class="work-venue">IEEE TIFS</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
          <a href="https://arxiv.org/abs/2312.15172" class="work-item" target="_blank">
            <div class="work-info">
            <h5>Pre-trained Trojan Attacks for Visual Recognition</h5>
            <p>This work introduces the Pre-trained Trojan attack, which embeds inheritable backdoors into pre-trained vision models (PVMs) to compromise various downstream tasks like object detection and segmentation.</p>
            <span class="work-venue">IJCV</span>
            </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/2103.01050" class="work-item" target="_blank">
        <div class="work-info">
          <h5>Dual Attention Suppression Attack: Generate Adversarial Camouflage in Physical World</h5>
          <p>This paper proposes the Dual Attention Suppression (DAS) attack, which creates visually natural and highly transferable physical adversarial camouflages by simultaneously suppressing both model attention and human visual attention.</p>
          <span class="work-venue">CVPR 2021</span>
          </div>
        <i class="fas fa-external-link-alt"></i>
        </a>
        </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- Replace with your paper title -->
            <h1 class="title is-1 publication-title">Exploring Semantically-constrained Adversarial Example with Instruction Uncertainty Reduction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://hujincn.github.io/" target="_blank">Jin Hu</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://jiakaiwangcn.github.io/" target="_blank">Jiakai Wang</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="" target="_blank">Linna Jing</a><sup></sup>,</span>
                    <span class="author-block">
                     <a href="https://lsyycf.github.io/" target="_blank">Haolin Li</a><sup></sup>,</span>
                     <span class="author-block">
                      <a href="" target="_blank">Haodong Liu</a><sup></sup>,</span>
                      <span class="author-block">
                       <a href="https://htqin.github.io/" target="_blank">Haotong Qin</a><sup></sup>,</span>
                       <span class="author-block">
                        <a href="https://liuaishan.github.io/" target="_blank">Aishan Liu</a><sup></sup>,</span>
                        <span class="author-block">
                         <a href="https://scse.buaa.edu.cn/info/1078/2655.htm" target="_blank">Ke Xu</a><sup></sup>,</span>
                         <span class="author-block">
                          <a href="https://xlliu-beihang.github.io/" target="_blank">Xianglong Liu</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- Replace with your institution and conference/journal info -->
                    <span class="author-block">State Key Laboratory of Complex & Critical Software Environment, Beihang University, Zhongguancun Laboratory 3School of Computer Science and Engineering, Beihang University, Dept. of Information Technology and Electrical Engineering, ETH Zurich<br>NeurIPS 2025</span>
                    <!-- Remove this line if no equal contribution -->
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/SemanticAE.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/lsyycf/SemanticAE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/forklift.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        This video demonstrates a generated 3D adversarial forklift. Our method creates semantically consistent 3D objects that can effectively fool vision models when rendered from multiple viewpoints.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- Replace with your paper abstract -->
          <p>
            Recently, semantically constrained adversarial examples (SemanticAE), which are directly generated from natural language instructions, have become a promising avenue for future research due to their flexible attacking forms, but have not been thoroughly explored yet. To generate SemanticAEs, current methods fall short of satisfactory attacking ability as the key underlying factors of semantic uncertainty in human instructions, such as referring diversity, descriptive incompleteness, and boundary ambiguity, have not been fully investigated. To tackle the issues, this paper develops a multi-dimensional instruction uncertainty reduction (InsUR) framework to generate more satisfactory SemanticAE, transferable, adaptive, and effective. Specifically, in the dimension of the sampling method, we propose the residual-driven attacking direction stabilization to alleviate the unstable adversarial optimization caused by the diversity of language references. By coarsely predicting the language-guided sampling process, the optimization process will be stabilized by the designed ResAdv-DDIM sampler, therefore releasing the transferable and robust adversarial capability of multi-step diffusion models. In task modeling, we propose the context-encoded attacking scenario constraint to supplement the missing knowledge from incomplete human instructions. Guidance masking and renderer integration are proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger scenario-adapted attacks. Moreover, in the dimension of generator evaluation, we propose the semantic-abstracted attacking evaluation enhancement by clarifying the evaluation boundary based on the label taxonomy, facilitating the development of more effective SemanticAE generators. Extensive experiments demonstrate the superiority of the transfer attack performance of InSUR. Besides, it is worth highlighting that we realize the reference-free generation of semantically constrained 3D adversarial examples by utilizing language-guided 3D generation models for the first time.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Method and Key Visualizations</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths"> <div>
            <img src="static/images/method.png" alt="InSUR Framework Overview" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
              Overview of the InSUR framework.
            </h2>
          </div>

          <div style="margin-top: 3rem;"> <img src="static/images/resadvddim.png" alt="ResAdv-DDIM Visualization" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
              Residual-driven attacking direction stabilization.
            </h2>
          </div>

          <div style="margin-top: 3rem;">
            <img src="static/images/2dvis.png" alt="2D SemanticAEs Visualization" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
             Visualization of 2D SemanticAEs.
           </h2>
         </div>

         <div style="margin-top: 3rem;">
          <img src="static/images/guidance_variance.png" alt="Inconsistent Guidance Problem" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            The inconsistent adversarial direction problem.
          </h2>
        </div>

        <div style="margin-top: 3rem;">
          <img src="static/images/3dpipe.png" alt="3D Optimization Pipeline" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            3D optimization pipeline for SemanticAE.
          </h2>
        </div>

        <div style="margin-top: 3rem;">
          <img src="static/images/3dvis.png" alt="3D SemanticAEs Visualization" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            Visualization of generated 3D SemanticAEs.
          </h2>
        </div>

        <div style="margin-top: 3rem;">
          <img src="static/images/coarse_label.png" alt="Abstract Label Evasion Task" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            Construction of the abstract label evasion task.
          </h2>
        </div>
        
        <div style="margin-top: 3rem;">
          <img src="static/images/placeholder.png" alt="Placeholder image" loading="lazy" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            Additional result or visualization.
          </h2>
        </div>

        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->



<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Generated 3D Adversarial Examples</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/volcano.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            A 3D adversarial volcano, demonstrating the model's ability to generate complex natural scenes.
          </h2>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/llama.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
            Generated 3D adversarial llama, preserving semantics while embedding robust adversarial patterns.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- Replace with your poster PDF -->
      <iframe  src="static/pdfs/SemanticAE.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{Hu2025SemanticAE,
  title={Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction},
  author={Hu, Jin and Wang, Jiakai and Jing, Linna and Li, Haolin and Liu, Haodong and Qin, Haotong and Liu, Aishan and Xu, Ke and Liu, Xianglong},
  journal={NeurIPS},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
